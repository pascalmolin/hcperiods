\documentclass[main.tex]{subfiles}

\begin{document}

  \section{Double-exponential integration}\label{sec:de_int}


For $(a,b) \in E$ we want to compute (see Theorem \ref{m-thm:periods}) 
\begin{align*}
 \int_{-1}^1 \frac{\varphi_{i,j}(u)}{(1-u^2)^{\frac{j}{m}}} \, \du 
\end{align*}
 to absolute precision $e^{-D}$.

Using the double-exponential change of variable
$u=\tanh(λ\sinh(t))$, the integral
becomes
\begin{equation}
    \int_{-1}^1 \frac{\varphi_{i,j}(u)}{(1-u^2)^{\frac{j}{m}}} \, \du = \int_\R g(t)\dt
\end{equation}
with $α=(1-j/m)$ and
\begin{equation}
   % g(t) = \frac{u(t)^{i-1}}{\fab(u(t))^j}\frac{λ\cosh(t)}{\cosh(λ\sinh(t))^{2α}}
   g(t) = \frac{\left(u(t)+\frac{b+a}{b-a}\right)^{i-1}}{\fab(u(t))^j}\frac{λ\cosh(t)}{\cosh(λ\sinh(t))^{2α}}
\end{equation}

Let
\begin{equation}
Z_τ = \set{\tanh(λ\sinh(z), -τ<\Im(z)<τ }    
\end{equation}
be the image of the strip $\Delta_τ$ under the change of
variable $u=\tanh(λ\sinh(t))$.

Since we can compute the distance of each branch point $u_i$ to
both $[-1,1]$ and its neighborhood $Z_\tau$, we obtain
  \begin{lemma}
      There exist explicitly computable
      constants $M_1$, $M_2$ such
      that
      \begin{itemize}
          %\item for $u\in[-1,1]$, $\abs{\frac{u^{i-1}}{\fab(u)^{j}}}\leq M_1$
          \item for $u\in[-1,1]$, $\abs{\frac{\left(u+\frac{b+a}{b-a}\right)^{i-1}}{\fab(u)^{j}}}\leq M_1$\,,
          %\item for $u\in Z_\tau$, $\abs{\frac{u^{i-1}}{\fab(u)^{j}}}\leq M_2$.
          \item for $u\in Z_\tau$, $\abs{\frac{\left(u+\frac{b+a}{b-a}\right)^{i-1}}{\fab(u)^{j}}}\leq M_2$\,.
      \end{itemize}
  \end{lemma}

We also introduce the following quantities
\begin{align}
    X_τ &=\cos(τ)\sqrt{\frac{π}{2λ\sinτ}-1} \\
    B(τ,α) &=
    \frac{2}{\cosτ}
    \left(
        \frac{X_τ}2(\frac1{\cos^{2α}(λ\sinτ)}+\frac1{X_τ^{2α}})
        +\frac{1}{2α\sinh^{2α}X_τ}
    \right)
\end{align}

Once computed the two bounds $M_1$, $M_2$ and the constant $B(τ,α)$,
we obtain a rigorous integration scheme as follows
\begin{thm}
    With the notations above, for all $D>0$, choose $h$ and $n$ such that
    \begin{equation}
        \begin{cases}
            h \le \frac{2πτ}{D + \log(2M_2 B(τ,α) + e^{-D})}\\
            nh \ge \asinh(\frac{D+\log(\frac{2^{2α+1}M_1}{α})}{2αλ})
        \end{cases}
    \end{equation}
    then
    \begin{equation}
        \abs{
            \int_{-1}^1 \varphi_{i,j}
            - h\sum_{k=-n}^n
            w_k \frac{u_k^{i-1}}{\fab(u_k)^j}
        } \leq e^{-D}
    \end{equation}
    where
    \begin{equation}
        \begin{cases} 
            u_k = \tanh(λ\sinh(kh))\\
            w_k = \frac{λ\cosh(kh)}{\cosh^{2α}(λ\sinh(kh)}
        \end{cases}
    \end{equation}
\end{thm}

The proof follows the same lines as the one in \cite{Molin2010}:
we write the Poisson formula on $h\Z$ for the function $g$
\begin{equation}
    \underbrace{h\sum_{\abs{k}>n}g(kh)}_{e_T}
 + h\sum_{k=-n}^n g(kh)
 = \int_\R g
 +
     \underbrace{\sum_{k\in\Z^\ast} \hat g(\frac{k}{h})}_{e_Q}
\end{equation}
and control both error terms $e_T$ and $e_q$ by lemma \ref{lem:de_error_trunc}
and \ref{lem:de_error_quad} below. The actual parameters $h$ and $n$ follow
by bounding each error by $e^{-D}/2$.

\begin{lemma}[truncation error]
    \label{lem:de_error_trunc}
    \begin{equation}
        \sum_{\abs{k}>n}\abs{hg(kh)}
        \leq \frac{2^{2α} M_1}{αλ}\exp(-2αλ\sinh(nh))
    \end{equation}
\end{lemma}
\begin{proof}
    We bound the sum by the integral of a decreasing function
    \begin{align*}
        \sum_{\abs{k}>n}\abs{hg(kh)}
        &\leq2M_1\int_{nh}^\infty\frac{λ\cosh(t)}{\cosh(λ\sinh(t))^{2α}}
        =2M_1\int_{λ\sinh(nh)}^\infty\frac{\dt}{\cosh(t)^{2α}}\\
        &\leq 2^{2α+1} M_1\int_{λ\sinh(nh)}^\infty e^{-2αt}\dt
        = \frac{2^{2α} M_1}{α}e^{-2αλ\sinh(nh)}
    \end{align*}
\end{proof}

\begin{lemma}[discretization error]
    \label{lem:de_error_quad}
    With the current notations,
    \begin{equation}
        \sum_{k\neq0}\abs{\hat g(\frac kh)}
        \leq
        \frac{M_2B(τ,α)}{e^{2πτ/h}-1}.
    \end{equation}
\end{lemma}


We first bound the Fourier transform by a shift of contour
\begin{equation}
    \forall X>0, \hat g(\pm X) = e^{-2πXτ} \int_{\R} g(t\mp iτ) e^{-2iπtX}\dt
\end{equation}
so that
\begin{equation}
    \sum_k \abs{\hat g(\frac kh)}
    \leq
    \frac{2M_2}{e^{2πτ/h}-1}\int_\R \abs{
    \frac{λ\cosh(t+iτ)}{\cosh(λ\sinh(t+iτ))^{2α}}}\dt
\end{equation}

Now the point $λ\sinh(t+iτ) = X(t)+iY(t)$ lies on the hyperbola
$Y^2 =λ^2(\sin^2τ+\tan^2 τX^2)$, and
\begin{align}
    \abs{λ\cosh(t+iτ)} &\leq λ\cosh(t) =\frac{X'(t)}{\cos(τ)}\\
    \abs{\cosh(X+iY)}^2 &= \sinh(X)^2+\cos(Y)^2 
\end{align}
so that
\begin{equation}
    \int_\R \abs{
    \frac{λ\cosh(t+iτ)}{\cosh(λ\sinh(t+iτ))^{2α}}}\dt
    \leq
    \frac{2}{\cosτ}\int_0^\infty\frac{\d X}{(\sinh(X)^2+\cos(Y)^2)^α}
\end{equation}
For $X_0=0$, $Y_0=λ\sinτ<\frac{π}2$, and $Y_τ=\frac{π}2$ for
$X_τ=\cos(τ)\sqrt{\frac{π}{2Y_0}-1}$.

  We cut the integral at $X=X_τ$ and write
  \begin{align}
      \int_0^{X_τ}\frac{\d X}{(\sinh(X)^2+\cos(Y)^2)^α}
      & \leq \int_0^{X_τ}\frac{\d X}{(X^2+\cos^2Y)^α} \\
      \int_{X_τ}^\infty\frac{\d X}{(\sinh(X)^2+\cos(Y)^2)^α}
      & \leq \int_{X_τ}^\infty\frac{\d X}{(\sinh X)^{2α}}
  \end{align}
  
  We bound the first integral by convexity:
  since $Y(X)$ is convex and $\cos$ is concave decreasing for $Y\leq Y_τ$ we
  obtain by concavity of the composition
  \begin{equation}
      \forall X\leq X_τ, \cos(Y)\geq \cos(Y_0)(1-\frac{X}{X_τ})
  \end{equation}
  Now $X^2+\cos^2Y\geq P_2(X)$ where
  \begin{equation}
     P_2(X) = X^2(1+\frac{\cos^2(Y_0)}{X_τ^2})-2\frac{\cos^2(Y_0)}{X_τ}X+\cos^2(Y_0)
  \end{equation}
  is a convex quadratic, so $X\mapsto P_2(X)^{-α}$ is still convex and the integral
  is bounded by one trapeze
  \begin{equation}
      \int_0^{X_τ}\frac{\d X}{P_2(X)^α}\leq X_τ\frac{P_2(0)+P_2(X_τ)}2
      = \frac{X_τ}2\left(\frac1{\cos^{2α}(Y_0)}+\frac1{X_τ^{2α}}\right)
  \end{equation}

  For the second integral we use
  $\sinh(X)\geq\sinh(X_τ)e^{X-X_τ}$ to obtain
  \begin{equation}
      \int_{X_τ}^\infty \frac{\d X}{\sinh(X)^{2α}} \leq \frac1{2α\sinh(X_τ)^{2α}}
  \end{equation}

\subsection{Gauss-Chebychev integration}
\label{sub:gauss_chebychev_integration}

In the case of hyperelliptic curves, we have $α=\frac12$ and the integral
\begin{equation}
    \int_{-1}^1\frac{\varphi_{i,j}(u)}{\sqrt{1-u^2}}\du
\end{equation}
can be efficiently handled by Gaussian integration with weight
$\sqrt{1-u^2}^{-1}$,
for which the corresponding orthogonal polynomials are 
Chebychev polynomials.

In this case, the integration formula is particularly
simple: there is no need to actually compute the Chebychev polynomials
since their roots are explicitly given as cosine functions.
\begin{thm}[Gauss-Chebychev integration]
    Let $g$ be holomorphic around $[-1,1]$. Then for all
    $n$, there exist $\xi \in ]-1,1[$ such that
    \begin{equation}
        \label{eq:gauss_chebychev}
        \int_{-1}^1\frac{g(u)}{\sqrt{1-u^2}}\du
        - \sum_{k=1}^n w_k g(u_k)
        = \frac{π2^{2n+1}}{2^{4n}}\frac{g^{(2n)}(\xi)}{(2n)!}
     = E(n),
    \end{equation}
    with constant weights $w_k = w =\frac{π}n$ and nodes $u_k = \cos(\frac{2k-1}{2n}π)$.
\end{thm}

Moreover, very nice estimates can by obtained by applying the residue
theorem on an ellipse $ε_r$ of the form
\begin{equation}
    ε_r = \set{z, \abs{z-1}+\abs{z+1} = 2r }
\end{equation}
Its foci are $\pm1$ and $r>1$ is the sum of half axis.

\begin{thm}[\cite{ChawlaJain68},thm 5]
    Let $r>1$ such that $g$ is holomorphic on $ε_r$. Then
    \begin{equation}
        \abs{E(n)}\leq \frac{2πM(r)}{r^{2n}-1}
    \end{equation}
    where $M(r)=\max\set{\abs{f(z)},z\in ε_r}$.
\end{thm}

Now $\varphi_{i,j}(u)=\frac{P(u)}{\sqrt{Q(u)}}$ for explicitely factored
polynomials
$P(u)=(u-c)^k$ and $Q(u)=\prod(u-u_i)$, and one can explicitely
compute the distance $d_r(u_i)$ from $u_i$ to the ellipse $ε_r$
by Newton iteration, so that the parameters can be chosen
as follows
\begin{prop}
    Let $r>1$ be such that $2r<\abs{u_i-1}+\abs{u_i+1}$ for all
    roots $u_i$ of $Q$, and let
    \begin{equation}
        M(r) =  \frac{(r+c)^k}{\sqrt{\prod d_r(u_i)} }
    \end{equation}
    then $E(n) \leq e^{-D}$ for all
    \begin{equation}
        n \geq \frac{D+\log(2πM(r))+1}{2\log(r)}
    \end{equation}
\end{prop}

More details on the choice of $r$ and the computation of $M(r)$
are given in section \ref{choice_r_ellipse}.

\iffalse
the $2n$-th derivative can be
estimated quite precisely by Cauchy formula.

\newcommand{\rmax}{r_{\mathrm{max}}}
\begin{lemma}
    Let $u_i$ be the roots of $Q$, and $r_i$ the distance from
    $u_i$ to $[-1,1]$. Let also $\rmax$ be the minimum of $r_i$.

    Then for all $r<\rmax$,
    \begin{equation}
    \abs{E_n} \leq \frac{2π}rB(r)(2r)^{-2n}
    \end{equation}
    where
    \begin{equation}
        B(r) = \frac1{\prod_i(r_i-r)}
    \end{equation}
\end{lemma}

For fixed $n$, assuming the minimum value $\rmax$ is attained for exactly
$m$ roots $u_i$, we can optimize the choice of $r$ by writing
$r=\rmax(1-λ)$ so that $B(r)\leq\frac{B_1}{(\rmaxλ)^m}$, where
$B_1=\prod(r_i-\rmax)$, the product being on those $r_i>\rmax$.

Then
\begin{equation}
    \frac{2π}rB(r)(2r)^{-2n}
    = \frac{2πB_1}{\rmax^m} λ^{-m}(2\rmax(1-λ))^{-2n-1}
\end{equation}
and $λ^m(1-λ)^{2n+1}$ is maximum for
\begin{equation}
    λ = \frac{m}{2n+1+m}
\end{equation}
in which case 
$λ^m(1-λ)^{2n+1}=(1+\frac{2n+1}m)^{-m}(1+\frac{m}{2n+1})^{-(2n+1)}$.

We therefore consider this value of $λ$, so that
\begin{equation}
    E(n) \leq 
    \frac{2πB_1}{\rmax^m}
    (1+\frac{2n+1}m)^m(1+\frac{m}{2n+1})^{2n+1}(2\rmax)^{-2n-1}
\end{equation}

  \begin{align}
      \sinh(x+iy) &= \sinh x\cos y+i\cosh x\sin y\\
      \cosh(x+iy) &= \cosh x\cos y+i\sinh x\sin y
  \end{align}
  so that writing $λ\sinh(t+iτ)=X+iY$ we express the integral in terms
  of $X,Y$ with
  \begin{align}
      X &= λ\sinh t\cosτ\\
      Y &= λ\cosh t\sinτ\\
      Y^2 =λ^2(\sin^2τ+\tan^2 τX^2)\\
      λ\cosh(t+iτ) &= λ\cosh t\cos τ+iλ\sinh t\sinτ \\
                     &= Y/\tan(τ) + i X\tan(τ)\\
      \abs{\cosh(X+iY)}^2
      &= \cosh^2 X\cos^2 Y+\sinh^2 X\sin^2 Y \label{eq:boundchcos}\\
      &= \sinh^2 X + \cos^2 Y \label{eq:boundchsh}
  \end{align}
\fi

\iffalse
assume(t,real);
assume(tau,real);
assume(l,real);
assume(l>0);
assume(l<Pi/2);
phi:=tanh(l*sinh(t+I*tau));;
simplify(expand(diff(phi,t$1)));
\fi


\biblio      
\end{document}
